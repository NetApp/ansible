---
# Using the block/rescue combination to let us loop until the node either fails
# or we transition to the desired state
- name: "Ensure the cluster is ready to have a node placed in maintenance mode"
  when: sf_in_maintenance_mode is defined and not sf_in_maintenance_mode
  block:
    - name: "Ensure MaintenanceMode is enabled for {{ target_name }}/{{ target_MIP }}/ID:{{ target_id }}"
      failed_when: >
        (sf_cluster_error is defined and sf_cluster_error) or (
        target_id is not defined and
        target_name.upper() != ansible_hostname.upper())

      run_once: True
      delegate_to: localhost
      uri:
        url: "https://{{ sf_mgmt_virt_ip }}:443/json-rpc/{{ sf_api_version }}"
        method: POST
        url_username: "{{ sf_cluster_admin_username }}"
        url_password: "{{ sf_cluster_admin_passwd }}"
        force_basic_auth: yes
        timeout: "{{ sf_cluster_connect_timeout }}"
        body_format: json
        body:
          method: 'EnableMaintenanceMode'
          params:
            forceWithUnresolvedFaults: "{{ yes_i_want_to_ignore_cluster_faults }}"
            timeout: "{{ sf_maint_mode_duration }}"
            nodes:
              - "{{ target_id }}"
        validate_certs: "{{ sf_validate_certs }}"
        use_proxy: "{{ sf_use_proxy }}"
        force: True
        status_code: 200
        follow_redirects: safe
      register: eRequest

    # No point in going through the status checks if maint. mode has been
    # changed to what we need it to be for the node already
    - name: "Ensure we save changes to status for {{ target_name }}/{{ target_MIP }}/ID:{{ target_id }}"
      set_fact:
        sf_in_maintenance_mode: True
        sf_attempts: 0
      when: >
        eRequest.json.result is not undefined and
        eRequest.json.result.currentMode is not undefined and
        eRequest.json.result.currentMode == 'ReadyForMaintenance'

    # Using the same checks for both the Enable and Disable maintenance mode
    # operation, so it's in a separate, included, task list
    - name: "Ensure we load status checks for {{ target_name }}/{{ target_MIP }}/ID:{{ target_id }}"
      when: not sf_in_maintenance_mode
      include_tasks: check-node-status.yml
      args:
        apply:
          delegate_to: "{{ target_MIP }}"
          run_once: True
          tags:
            - check-node-status
      vars:
        request: "{{ eRequest }}"
        target_status: 'ReadyForMaintenance'

    - name: "Ensure we loop if maintenance mode isn't enabled yet for {{ target_name }}/{{ target_MIP }}/ID:{{ target_id }}"
      fail:
        msg: "Retry: Need to wait until {{ target_name }}/{{ target_MIP }}/ID:{{ target_id }} enters maintenance mode"
      when: not sf_in_maintenance_mode

  # Using the block/rescue combination to let us loop until the node either fails
  # or we transition to the desired state
  rescue:
    - name: "Ensure we exit if there are unexpected cluster errors {{ target_name }}/{{ target_MIP }}/ID:{{ target_id }}"
      fail:
        msg: "Error: Cannot upgrade cluster!"
      when: (sf_cluster_error is defined and sf_cluster_error)

    # Future proofing
    - name: Ensure we handle expected 500 statuses from the API
      set_fact:
        sf_in_maintenance_mode: True
      when: >
        eRequest.json.error is defined and
        eRequest.json.error.name is defined and
        eRequest.json.error.name == 'xAlreadyInRequestedMode'

    # Informational message.
    #
    # We fail the node by skipping through to the end of the
    # upgrade-node tasks after this
    - debug:
        msg: "Can't upgrade {{ target_name }}/{{ target_MIP }}/ID:{{ target_id }}. Something went wrong!"
      when: >
        not sf_in_maintenance_mode and sf_cluster_error

    # Increment our retry iteration counter
    - set_fact:
        sf_attempts: "{{ sf_attempts | default(0) | int + 1 }}"
      no_log: True
      when: not sf_in_maintenance_mode and not sf_cluster_error

    # Have to give up. We've waited for wait_time * number of attempts
    # By default, this would be 90 minutes for the EnableMaintenanceMode operation,
    # on one node, alone
    - fail:
        msg: "Number of attempts exceed {{ sf_max_poll_attempts }}"
      when: >
        not sf_in_maintenance_mode and not sf_cluster_error and
        (sf_attempts | int) > (sf_max_poll_attempts | int)

    - name: "Ensure we need to wait ({{ sf_attempts }} of {{ sf_max_poll_attempts }})"
      set_fact:
          sf_still_waiting: "{{ not sf_in_maintenance_mode and
            (sf_attempts|int) <= (sf_max_poll_attempts|int) }}"
      no_log: True

    - pause:
        prompt: "Wait {{ sf_wait_delay }} secs to retry EnableMaintenanceMode on {{ target_name }}/{{ target_MIP }}/ID:{{ target_id }}"
        seconds: "{{ sf_wait_delay }}"
      when: not sf_cluster_error and not sf_in_maintenance_mode and sf_still_waiting
      no_log: True

    # This is how we loop on the EnableMaintenanceMode API check until
    # the node has exited the transition. We call ourselves recursively
    # for up to sf_max_poll_attempts iterations
    - name: Ensure we (re)load EnableMaintenanceMode check
      when: >
        (not sf_in_maintenance_mode) and sf_still_waiting and
        (sf_cluster_error is undefined or
        (sf_cluster_error is not undefined and not sf_cluster_error))
      include_tasks: activate-node-maintenance-mode.yml
